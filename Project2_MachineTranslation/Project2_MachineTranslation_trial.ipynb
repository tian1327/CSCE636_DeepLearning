{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TianLiu_525004380_Project2_MachineTranslation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Solution Explanation:"
      ],
      "metadata": {
        "id": "as-LqlwFjblf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzHKLaH_pBtQ",
        "outputId": "ff7ead8f-20f4-4fef-82b5-d9db179f9ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 00:11:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPhqRD_spRYr",
        "outputId": "8cfadc92-078c-4b6b-b756-b38c65898bc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 'drive/MyDrive/Colab Notebooks/CSCE636_DeepLearning/Project2_MachineTranslation/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0PiivhHpTkK",
        "outputId": "76a094cb-5165-440c-cf34-f9a92ecbdadf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/CSCE636_DeepLearning/Project2_MachineTranslation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Training Data"
      ],
      "metadata": {
        "id": "n1ChsCdcpaCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "train_input = pickle.load(open('DS_5_train_input', 'rb'))\n",
        "train_output = pickle.load(open('DS_5_train_output', 'rb'))\n",
        "\n",
        "# check dimension\n",
        "print(type(train_input), type(train_input[0]), len(train_input))\n",
        "print(type(train_output), type(train_output[0]), len(train_output))\n",
        "\n",
        "# get the max num of words in train input and output to determine sequence_length\n",
        "# get the max length of a word to determine vocabulary size\n",
        "\n",
        "max_ct = 0\n",
        "max_len = 0\n",
        "vocab_set = set()\n",
        "for text in train_input:\n",
        "  ct = len(text.split())\n",
        "  for word in text.split():\n",
        "    vocab_set.add(word)\n",
        "    length = len(word)\n",
        "    max_len = max(max_len, length)\n",
        "  max_ct = max(max_ct, ct)\n",
        "\n",
        "print('vocab_size in train_input:', len(vocab_set))\n",
        "print('max num of words in train_input:', max_ct)\n",
        "print('max length of a word in train_input:', max_len)\n",
        "print()\n",
        "\n",
        "max_ct = 0\n",
        "max_len = 0\n",
        "vocab_set = set()\n",
        "for text in train_output:\n",
        "  ct = len(text.split())\n",
        "  for word in text.split():\n",
        "    vocab_set.add(word)\n",
        "    length = len(word)\n",
        "    max_len = max(max_len, length)  \n",
        "  max_ct = max(max_ct, ct)\n",
        "\n",
        "print('vocab_size in train_output:', len(vocab_set))\n",
        "print('max num of words in train_output:', max_ct)\n",
        "print('max length of a word in train_output:', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sblPcAcxprZp",
        "outputId": "595ac57f-e79c-47d5-a537-9c36e41a8929"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'str'> 5000\n",
            "<class 'list'> <class 'str'> 5000\n",
            "vocab_size in train_input: 11\n",
            "max num of words in train_input: 64\n",
            "max length of a word in train_input: 1\n",
            "\n",
            "vocab_size in train_output: 34\n",
            "max num of words in train_output: 95\n",
            "max length of a word in train_output: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess Data"
      ],
      "metadata": {
        "id": "reBhJBsFGamk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert [start] and [end] to the output language\n",
        "\n",
        "text_pairs = []\n",
        "for i in range(len(train_input)):\n",
        "  input = train_input[i]\n",
        "  output = \"[start] \" + train_output[i].strip() + \" [end]\" # strip off the whitespaces\n",
        "  text_pairs.append((input, output))"
      ],
      "metadata": {
        "id": "E_RsBPj-IiJE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check sample text pairs\n",
        "from numpy import random\n",
        "\n",
        "num_sample = 10\n",
        "idx = [random.randint(0, len(train_input)) for i in range(num_sample)]\n",
        "\n",
        "for i in idx:\n",
        "  print(\"idx =\", i)\n",
        "  print(len(text_pairs[i][0].split()), text_pairs[i][0])\n",
        "  print(\"->\")\n",
        "  print(len(text_pairs[i][1].split())-2, text_pairs[i][1])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOUwxQMb__zQ",
        "outputId": "3a02af6a-131c-427c-fc35-4f127820c9ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx = 916\n",
            "46 a f b f a j a e c d c d a f a k b e a d b g a k c g a k a f b d c d c f a f c e a f b e c g \n",
            "->\n",
            "68 [start] b f c d a e e c d b e b g c g b d c d a f k l c f a k m ed a k j ee a d i ef a k h eg c e b e c g a f ej ek a f ei el a f eh em a j f g fd a f d fe [end]\n",
            "\n",
            "idx = 3448\n",
            "32 a i a j a d b f a e a d a f c d b e b d b e b f a d b e c d b g \n",
            "->\n",
            "47 [start] b f c d b e a f e f b d a d g h a e i a d d j b e b f a j k l m b e c d a d ee ef b g a i ed eg eh [end]\n",
            "\n",
            "idx = 322\n",
            "58 a g a j b d a f b d c e c f a e a d a g a d b e b f a h c g a k a d a f b g a f a g b g c d a e b e c f c g b f b d \n",
            "->\n",
            "86 [start] b d b d c e a f e f c f a j d g h b e b f a d j k c g b g b g c d a g ee ef b e a e eh a f eg ei a f ed ej c f a d ek el c g a k em fd b f a h m fe ff a g l fg b d a d fh fi a e fj a g i fk [end]\n",
            "\n",
            "idx = 717\n",
            "40 a h c d a d a j c e c f c g a f c d a g a k a e c d a e a g c g a e c f b g c e \n",
            "->\n",
            "59 [start] c d c e c f c g a j e f g c d c d a e j c g c f a e m a g l ed a e ee a k k ef b g a g eg eh a f i ei a d h ej c e a h d ek el [end]\n",
            "\n",
            "idx = 4901\n",
            "32 a j b g c e a f a k c g c g a f a d b d a e a h c f c f b f b e \n",
            "->\n",
            "47 [start] b g c e c g c g a k f g b d c f c f b f a h j k l a e m a d i ed b e a f ee ef a f h eg a j d e eh [end]\n",
            "\n",
            "idx = 773\n",
            "40 a i a j b d a f a e a e a e b d c f a i b g a g c f b e a j b d c d b e b e c d \n",
            "->\n",
            "59 [start] b d b d a e e a e f a e g c f a f h i b g c f b e a g l m b d c d b e a j ee ef eg a i k ed eh a j d j ei b e c d a i ej ek el [end]\n",
            "\n",
            "idx = 1862\n",
            "34 a h b f a h b f b e a j c e c e a d a g a k c e b f c g c f a e b g \n",
            "->\n",
            "50 [start] b f b f b e c e c e c e b f a k i j c g a g k l c f a d m ed a j g h ee a h e f ef b g a e eh a h d eg ei [end]\n",
            "\n",
            "idx = 4486\n",
            "52 a f c f a f c e a k c f a e a e a j a k b d b f a h a e b d a g c d c d a d b d a f a f b g c g b e c g \n",
            "->\n",
            "77 [start] c f c e c f b d b f a k g h b d a e j c d c d a g l m b d b g c g a f ef eg b e a f eh ei a d ee ej a h k ed ek c g a j i el em a e fd a e fe a k f ff a f e fg a f d fh [end]\n",
            "\n",
            "idx = 2992\n",
            "38 a g a f a k b g b f a d a h a g b g c d c g c d c g a f a d b e a e c f c d \n",
            "->\n",
            "56 [start] b g b f a k d e b g c d a g g h c g c d a h i j k c g a d l m a f f ed b e c f a e eg a d ef eh c d a f ei ej a g ee ek [end]\n",
            "\n",
            "idx = 2323\n",
            "40 a j b f a d a k b f a j c e a i c f b g a d b f a e c g b f a e b f a g c f b e \n",
            "->\n",
            "59 [start] b f b f c e c f b g b f c g a e j a d i k a i g h l b f a j f m ed a k e ee b f a e eg a d ef eh c f b e a g ej ek a j d ei el [end]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split training data into train and val set"
      ],
      "metadata": {
        "id": "wATDyPV2BkZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - num_val_samples\n",
        "\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:]\n",
        "\n",
        "print(len(train_pairs))\n",
        "print(len(val_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmpPueY1BqxR",
        "outputId": "224bb9eb-0877-4f5c-a2cd-6818beac2688"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4250\n",
            "750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save text_pairs\n",
        "import pickle\n",
        "\n",
        "with open('text_pairs', \"wb\") as out_file:\n",
        "  pickle.dump(text_pairs, out_file)\n",
        "\n",
        "# with open('train_pairs', \"wb\") as out_file:\n",
        "#   pickle.dump(train_pairs, out_file)\n",
        "\n",
        "# with open('val_pairs', \"wb\") as out_file:\n",
        "#   pickle.dump(val_pairs, out_file)"
      ],
      "metadata": {
        "id": "AZ8e3QIMVhYV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorizing the input and output text pairs"
      ],
      "metadata": {
        "id": "MNy0pg8nNIKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import string\n",
        "import re\n",
        "\n",
        "strip_chars = string.punctuation\n",
        "# print(type(strip_chars))\n",
        "\n",
        "strip_chars = strip_chars.replace(\"[\", \"\") # will keep [start] and [end] as it is to separate the marker from actual word start and end\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\") # replace punctuation characters with the empty string\n",
        "\n",
        "input_vocab_size = 100\n",
        "output_vocab_size = 100\n",
        "\n",
        "sequence_length = 100 # max seq length seen in train data is 95\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=input_vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=output_vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_input_texts = [pair[0] for pair in text_pairs] # here use all given training data\n",
        "train_output_texts = [pair[1] for pair in text_pairs]\n",
        "\n",
        "source_vectorization.adapt(train_input_texts)\n",
        "target_vectorization.adapt(train_output_texts)\n",
        "\n",
        "print(len(source_vectorization.get_vocabulary()))\n",
        "print(len(target_vectorization.get_vocabulary()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS53HEPsNDCd",
        "outputId": "d2f82668-b137-4a08-e034-69c0645a8640"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparing datasets for the translation task"
      ],
      "metadata": {
        "id": "Y55NKNKVYRFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "def format_dataset(input, output):\n",
        "    input = source_vectorization(input)\n",
        "    output = target_vectorization(output)\n",
        "    return ({\n",
        "        \"input\": input,\n",
        "        \"output\": output[:, :-1],\n",
        "      }, output[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n",
        "\n",
        "print(type(val_ds))\n",
        "\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['input'].shape: {inputs['input'].shape}\")\n",
        "    print(f\"inputs['output'].shape: {inputs['output'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVQDsTO8Ybe2",
        "outputId": "96f20867-7013-4bed-a5d4-671df8bea22e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.CacheDataset'>\n",
            "inputs['input'].shape: (64, 100)\n",
            "inputs['output'].shape: (64, 100)\n",
            "targets.shape: (64, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Transformer for Machine Translation"
      ],
      "metadata": {
        "id": "84Z2u9wTZjlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer Encoder"
      ],
      "metadata": {
        "id": "pHMT4BTwdTyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "BE-hu6tuZp_e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using positional encoding to re-inject order information"
      ],
      "metadata": {
        "id": "uX8s8mK6dlWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions # add up the word embedding and position embedding\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "watZVDGUdnZf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer Decoder"
      ],
      "metadata": {
        "id": "6K8UQKA0eUkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ],
      "metadata": {
        "id": "azE53LxieT5_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text Decoder"
      ],
      "metadata": {
        "id": "RDl6W2lfV_4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 100\n",
        "\n",
        "def strip_markers(sentence):\n",
        "  # strip the leading [start] and tailing [end] if existing\n",
        "\n",
        "  words = sentence.split()\n",
        "  if words[0] == \"[start]\":\n",
        "    clean_words = words[1:]\n",
        "  else:\n",
        "    clean_words = words\n",
        "  \n",
        "  if clean_words[-1] == \"[end]\":\n",
        "    clean_words = clean_words[:-1]\n",
        "  else:\n",
        "    clean_words = clean_words\n",
        "\n",
        "  clean_text = \" \".join(clean_words)\n",
        "  return clean_text\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "SJVrO1r9V-no"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### End-to-end Transformer"
      ],
      "metadata": {
        "id": "_AUcc_U4el7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 1024\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"input\")\n",
        "x = PositionalEmbedding(sequence_length, input_vocab_size, embed_dim)(encoder_inputs)\n",
        "# x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) # stack up transformerencoder layers\n",
        "# x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "# x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"output\")\n",
        "x = PositionalEmbedding(sequence_length, input_vocab_size, embed_dim)(decoder_inputs)\n",
        "# x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(output_vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "ePRujmOGeb0K"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the sequence-to-sequence Transformer"
      ],
      "metadata": {
        "id": "CUn5wMYkfnoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check how the accuracy metric is calculated in Keras\n",
        "import tensorflow as tf\n",
        "\n",
        "m = tf.keras.metrics.Accuracy()\n",
        "m.update_state([[1,100], [2, 200]], [[1, 200], [3, 300]])\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMk_ABtG4Zst",
        "outputId": "1a4488bd-0000-4d0e-85da-6f3d4ef246c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# turns out the Keras metric acc is very close to the word accuracy, no need for customied callbacks\n",
        "\"\"\"\n",
        "def calculate_word_acc(target_texts, pred_texts):\n",
        "\n",
        "  total_ct = 0\n",
        "  match_ct = 0\n",
        "\n",
        "  assert(len(target_texts)==len(pred_texts)) # assert target sentence number match pred sentence number\n",
        "  \n",
        "  text_pairs = zip(target_texts, pred_texts) \n",
        "  for pair in text_pairs: # loop through each sentence\n",
        "    target = pair[0]\n",
        "    pred = pair[1]\n",
        "\n",
        "    target_words = target.split()\n",
        "    pred_words = pred.split()\n",
        "\n",
        "    total_ct += len(target_words)\n",
        "    min_len = min(len(target_words), len(pred_words))\n",
        "    \n",
        "    for i in range(min_len): # loop through each word\n",
        "      if target_words[i] == pred_words[i]:\n",
        "        match_ct += 1\n",
        "    \n",
        "  word_acc = match_ct / total_ct\n",
        "  return word_acc\n",
        "\n",
        "\n",
        "train_word_acc = []\n",
        "val_word_acc = []\n",
        "\n",
        "# define customized metric as callback function, but very slow\n",
        "class WordAccuracy(keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.train_word_acc = 0 \n",
        "        self.val_word_acc = 0 \n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "\n",
        "        # train_word_acc\n",
        "        # train_input_texts = [pair[0] for pair in train_pairs]\n",
        "        # train_output_texts = [strip_markers(pair[1]) for pair in train_pairs]\n",
        "\n",
        "        # train_pred_texts = []\n",
        "        # for input_sentence in train_input_texts:\n",
        "        #   pred_sentence = strip_markers(decode_sequence(input_sentence))\n",
        "        #   train_pred_texts.append(pred_sentence)\n",
        "        # self.train_word_acc = calculate_word_acc(train_output_texts, train_pred_texts)\n",
        "\n",
        "        # val_word_acc\n",
        "        val_input_texts = [pair[0] for pair in val_pairs]\n",
        "        val_output_texts = [strip_markers(pair[1]) for pair in val_pairs]\n",
        "\n",
        "        val_pred_texts = []\n",
        "        for input_sentence in val_input_texts:\n",
        "          pred_sentence = strip_markers(decode_sequence(input_sentence))\n",
        "          val_pred_texts.append(pred_sentence)\n",
        "\n",
        "        self.val_word_acc = calculate_word_acc(val_output_texts, val_pred_texts)\n",
        "\n",
        "        # collect\n",
        "\n",
        "        # train_word_acc.append(self.train_word_acc)\n",
        "        val_word_acc.append(self.val_word_acc)\n",
        "      \n",
        "        print(\"train_word_auc = {:.4f}, val_word_auc = {:.4f}\".format(\\\n",
        "              self.train_word_acc, self.val_word_acc))\n",
        "\"\"\"\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "# word_auc = WordAccuracy()\n",
        "# history = transformer.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[word_auc])\n",
        "\n",
        "history = transformer.fit(train_ds, epochs=100, validation_data=val_ds, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpVEhXb1fnNp",
        "outputId": "f38bf3c7-cb89-41bf-b840-238b7c55accc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "67/67 [==============================] - 18s 156ms/step - loss: 2.3202 - accuracy: 0.1327 - val_loss: 1.3757 - val_accuracy: 0.2663\n",
            "Epoch 2/100\n",
            "67/67 [==============================] - 9s 142ms/step - loss: 1.3258 - accuracy: 0.2928 - val_loss: 1.1281 - val_accuracy: 0.3228\n",
            "Epoch 3/100\n",
            "67/67 [==============================] - 10s 143ms/step - loss: 1.1610 - accuracy: 0.3367 - val_loss: 1.2090 - val_accuracy: 0.3428\n",
            "Epoch 4/100\n",
            "67/67 [==============================] - 10s 144ms/step - loss: 1.0823 - accuracy: 0.3661 - val_loss: 0.9979 - val_accuracy: 0.3856\n",
            "Epoch 5/100\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 1.0397 - accuracy: 0.3818 - val_loss: 0.9405 - val_accuracy: 0.4193\n",
            "Epoch 6/100\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.9975 - accuracy: 0.3981 - val_loss: 0.9509 - val_accuracy: 0.4054\n",
            "Epoch 7/100\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.9643 - accuracy: 0.4116 - val_loss: 0.8723 - val_accuracy: 0.4457\n",
            "Epoch 8/100\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 0.9309 - accuracy: 0.4250 - val_loss: 0.8810 - val_accuracy: 0.4379\n",
            "Epoch 9/100\n",
            "67/67 [==============================] - 10s 148ms/step - loss: 0.9082 - accuracy: 0.4337 - val_loss: 0.8474 - val_accuracy: 0.4543\n",
            "Epoch 10/100\n",
            "67/67 [==============================] - 10s 149ms/step - loss: 0.8796 - accuracy: 0.4465 - val_loss: 0.8378 - val_accuracy: 0.4576\n",
            "Epoch 11/100\n",
            "67/67 [==============================] - 10s 149ms/step - loss: 0.8469 - accuracy: 0.4591 - val_loss: 0.7893 - val_accuracy: 0.4817\n",
            "Epoch 12/100\n",
            "67/67 [==============================] - 10s 150ms/step - loss: 0.8238 - accuracy: 0.4677 - val_loss: 0.7759 - val_accuracy: 0.4768\n",
            "Epoch 13/100\n",
            "67/67 [==============================] - 10s 150ms/step - loss: 0.8046 - accuracy: 0.4789 - val_loss: 0.7878 - val_accuracy: 0.4926\n",
            "Epoch 14/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.7791 - accuracy: 0.4897 - val_loss: 0.7135 - val_accuracy: 0.5177\n",
            "Epoch 15/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.7716 - accuracy: 0.4945 - val_loss: 0.6890 - val_accuracy: 0.5333\n",
            "Epoch 16/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.7461 - accuracy: 0.5054 - val_loss: 0.6924 - val_accuracy: 0.5247\n",
            "Epoch 17/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.7249 - accuracy: 0.5148 - val_loss: 0.7249 - val_accuracy: 0.5136\n",
            "Epoch 18/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.6999 - accuracy: 0.5284 - val_loss: 0.6936 - val_accuracy: 0.5263\n",
            "Epoch 19/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.6875 - accuracy: 0.5344 - val_loss: 0.6562 - val_accuracy: 0.5475\n",
            "Epoch 20/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.6728 - accuracy: 0.5432 - val_loss: 0.6501 - val_accuracy: 0.5533\n",
            "Epoch 21/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.6640 - accuracy: 0.5525 - val_loss: 0.6388 - val_accuracy: 0.5548\n",
            "Epoch 22/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.6471 - accuracy: 0.5601 - val_loss: 0.6153 - val_accuracy: 0.5731\n",
            "Epoch 23/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.6298 - accuracy: 0.5699 - val_loss: 0.6510 - val_accuracy: 0.5577\n",
            "Epoch 24/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.6261 - accuracy: 0.5741 - val_loss: 0.5797 - val_accuracy: 0.5986\n",
            "Epoch 25/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.6092 - accuracy: 0.5834 - val_loss: 0.5870 - val_accuracy: 0.5947\n",
            "Epoch 26/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.5939 - accuracy: 0.5943 - val_loss: 0.5778 - val_accuracy: 0.6059\n",
            "Epoch 27/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.5943 - accuracy: 0.5956 - val_loss: 0.5861 - val_accuracy: 0.5970\n",
            "Epoch 28/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.5735 - accuracy: 0.6072 - val_loss: 0.5945 - val_accuracy: 0.6001\n",
            "Epoch 29/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.5746 - accuracy: 0.6104 - val_loss: 0.5469 - val_accuracy: 0.6265\n",
            "Epoch 30/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.5644 - accuracy: 0.6192 - val_loss: 0.5429 - val_accuracy: 0.6326\n",
            "Epoch 31/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.5482 - accuracy: 0.6305 - val_loss: 0.6054 - val_accuracy: 0.6168\n",
            "Epoch 32/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.5400 - accuracy: 0.6430 - val_loss: 0.5386 - val_accuracy: 0.6462\n",
            "Epoch 33/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.5266 - accuracy: 0.6542 - val_loss: 0.5401 - val_accuracy: 0.6451\n",
            "Epoch 34/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.5103 - accuracy: 0.6666 - val_loss: 0.4959 - val_accuracy: 0.6734\n",
            "Epoch 35/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.4965 - accuracy: 0.6759 - val_loss: 0.5801 - val_accuracy: 0.6369\n",
            "Epoch 36/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.4956 - accuracy: 0.6805 - val_loss: 0.5885 - val_accuracy: 0.6346\n",
            "Epoch 37/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.4742 - accuracy: 0.6907 - val_loss: 0.4737 - val_accuracy: 0.6863\n",
            "Epoch 38/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.4655 - accuracy: 0.6960 - val_loss: 0.4778 - val_accuracy: 0.6837\n",
            "Epoch 39/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.4614 - accuracy: 0.7002 - val_loss: 0.4442 - val_accuracy: 0.7104\n",
            "Epoch 40/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.4369 - accuracy: 0.7141 - val_loss: 0.4702 - val_accuracy: 0.6987\n",
            "Epoch 41/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.4324 - accuracy: 0.7195 - val_loss: 0.4362 - val_accuracy: 0.7134\n",
            "Epoch 42/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.4192 - accuracy: 0.7270 - val_loss: 0.4390 - val_accuracy: 0.7185\n",
            "Epoch 43/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.4114 - accuracy: 0.7336 - val_loss: 0.4265 - val_accuracy: 0.7212\n",
            "Epoch 44/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.4013 - accuracy: 0.7400 - val_loss: 0.4081 - val_accuracy: 0.7351\n",
            "Epoch 45/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.3899 - accuracy: 0.7470 - val_loss: 0.4352 - val_accuracy: 0.7226\n",
            "Epoch 46/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.3803 - accuracy: 0.7547 - val_loss: 0.3689 - val_accuracy: 0.7586\n",
            "Epoch 47/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.3688 - accuracy: 0.7635 - val_loss: 0.3997 - val_accuracy: 0.7295\n",
            "Epoch 48/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.3574 - accuracy: 0.7704 - val_loss: 0.3788 - val_accuracy: 0.7555\n",
            "Epoch 49/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.3472 - accuracy: 0.7784 - val_loss: 0.3974 - val_accuracy: 0.7331\n",
            "Epoch 50/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.3388 - accuracy: 0.7851 - val_loss: 0.3491 - val_accuracy: 0.7766\n",
            "Epoch 51/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.3273 - accuracy: 0.7925 - val_loss: 0.3490 - val_accuracy: 0.7702\n",
            "Epoch 52/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.3178 - accuracy: 0.7993 - val_loss: 0.3579 - val_accuracy: 0.7840\n",
            "Epoch 53/100\n",
            "67/67 [==============================] - 10s 156ms/step - loss: 0.3107 - accuracy: 0.8041 - val_loss: 0.3392 - val_accuracy: 0.7896\n",
            "Epoch 54/100\n",
            "67/67 [==============================] - 10s 157ms/step - loss: 0.2978 - accuracy: 0.8116 - val_loss: 0.3131 - val_accuracy: 0.8030\n",
            "Epoch 55/100\n",
            "67/67 [==============================] - 11s 158ms/step - loss: 0.2904 - accuracy: 0.8176 - val_loss: 0.3348 - val_accuracy: 0.7928\n",
            "Epoch 56/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.2851 - accuracy: 0.8219 - val_loss: 0.4078 - val_accuracy: 0.7802\n",
            "Epoch 57/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.2748 - accuracy: 0.8283 - val_loss: 0.2926 - val_accuracy: 0.8157\n",
            "Epoch 58/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.2717 - accuracy: 0.8319 - val_loss: 0.3252 - val_accuracy: 0.7974\n",
            "Epoch 59/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.2575 - accuracy: 0.8395 - val_loss: 0.3123 - val_accuracy: 0.8064\n",
            "Epoch 60/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.2560 - accuracy: 0.8430 - val_loss: 0.3803 - val_accuracy: 0.7754\n",
            "Epoch 61/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.2479 - accuracy: 0.8474 - val_loss: 0.2970 - val_accuracy: 0.8172\n",
            "Epoch 62/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.2398 - accuracy: 0.8508 - val_loss: 0.2906 - val_accuracy: 0.8243\n",
            "Epoch 63/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.2392 - accuracy: 0.8530 - val_loss: 0.2558 - val_accuracy: 0.8442\n",
            "Epoch 64/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.2256 - accuracy: 0.8619 - val_loss: 0.2856 - val_accuracy: 0.8231\n",
            "Epoch 65/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.2296 - accuracy: 0.8609 - val_loss: 0.2931 - val_accuracy: 0.8270\n",
            "Epoch 66/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.2143 - accuracy: 0.8696 - val_loss: 0.2932 - val_accuracy: 0.8182\n",
            "Epoch 67/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.2105 - accuracy: 0.8721 - val_loss: 0.2965 - val_accuracy: 0.8245\n",
            "Epoch 68/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.2082 - accuracy: 0.8739 - val_loss: 0.2571 - val_accuracy: 0.8464\n",
            "Epoch 69/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.2010 - accuracy: 0.8776 - val_loss: 0.2548 - val_accuracy: 0.8516\n",
            "Epoch 70/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1931 - accuracy: 0.8831 - val_loss: 0.2635 - val_accuracy: 0.8489\n",
            "Epoch 71/100\n",
            "67/67 [==============================] - 10s 156ms/step - loss: 0.1921 - accuracy: 0.8837 - val_loss: 0.2590 - val_accuracy: 0.8494\n",
            "Epoch 72/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1898 - accuracy: 0.8881 - val_loss: 0.2578 - val_accuracy: 0.8489\n",
            "Epoch 73/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.1766 - accuracy: 0.8927 - val_loss: 0.2296 - val_accuracy: 0.8690\n",
            "Epoch 74/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.1809 - accuracy: 0.8921 - val_loss: 0.2821 - val_accuracy: 0.8394\n",
            "Epoch 75/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.1722 - accuracy: 0.8984 - val_loss: 0.2521 - val_accuracy: 0.8548\n",
            "Epoch 76/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.1668 - accuracy: 0.9009 - val_loss: 0.2592 - val_accuracy: 0.8532\n",
            "Epoch 77/100\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.1602 - accuracy: 0.9049 - val_loss: 0.2345 - val_accuracy: 0.8689\n",
            "Epoch 78/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.1615 - accuracy: 0.9046 - val_loss: 0.2209 - val_accuracy: 0.8751\n",
            "Epoch 79/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1542 - accuracy: 0.9092 - val_loss: 0.2031 - val_accuracy: 0.8828\n",
            "Epoch 80/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.1490 - accuracy: 0.9121 - val_loss: 0.2789 - val_accuracy: 0.8493\n",
            "Epoch 81/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.1490 - accuracy: 0.9120 - val_loss: 0.3298 - val_accuracy: 0.8426\n",
            "Epoch 82/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.1434 - accuracy: 0.9168 - val_loss: 0.2114 - val_accuracy: 0.8844\n",
            "Epoch 83/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.1377 - accuracy: 0.9189 - val_loss: 0.2460 - val_accuracy: 0.8665\n",
            "Epoch 84/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1353 - accuracy: 0.9204 - val_loss: 0.2635 - val_accuracy: 0.8529\n",
            "Epoch 85/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.1324 - accuracy: 0.9231 - val_loss: 0.2780 - val_accuracy: 0.8536\n",
            "Epoch 86/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1313 - accuracy: 0.9247 - val_loss: 0.2315 - val_accuracy: 0.8766\n",
            "Epoch 87/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.1247 - accuracy: 0.9274 - val_loss: 0.2567 - val_accuracy: 0.8593\n",
            "Epoch 88/100\n",
            "67/67 [==============================] - 10s 155ms/step - loss: 0.1236 - accuracy: 0.9277 - val_loss: 0.1932 - val_accuracy: 0.8960\n",
            "Epoch 89/100\n",
            "67/67 [==============================] - 10s 156ms/step - loss: 0.1249 - accuracy: 0.9283 - val_loss: 0.2206 - val_accuracy: 0.8824\n",
            "Epoch 90/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1117 - accuracy: 0.9355 - val_loss: 0.2007 - val_accuracy: 0.8959\n",
            "Epoch 91/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1148 - accuracy: 0.9334 - val_loss: 0.2021 - val_accuracy: 0.8965\n",
            "Epoch 92/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.1095 - accuracy: 0.9369 - val_loss: 0.2521 - val_accuracy: 0.8763\n",
            "Epoch 93/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.1097 - accuracy: 0.9374 - val_loss: 0.2394 - val_accuracy: 0.8736\n",
            "Epoch 94/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.1116 - accuracy: 0.9382 - val_loss: 0.2136 - val_accuracy: 0.8932\n",
            "Epoch 95/100\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.1047 - accuracy: 0.9403 - val_loss: 0.2001 - val_accuracy: 0.8998\n",
            "Epoch 96/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.0997 - accuracy: 0.9430 - val_loss: 0.2563 - val_accuracy: 0.8790\n",
            "Epoch 97/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.1007 - accuracy: 0.9432 - val_loss: 0.2127 - val_accuracy: 0.8954\n",
            "Epoch 98/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.0950 - accuracy: 0.9464 - val_loss: 0.1946 - val_accuracy: 0.9050\n",
            "Epoch 99/100\n",
            "67/67 [==============================] - 10s 154ms/step - loss: 0.0974 - accuracy: 0.9449 - val_loss: 0.2106 - val_accuracy: 0.8997\n",
            "Epoch 100/100\n",
            "67/67 [==============================] - 10s 153ms/step - loss: 0.0898 - accuracy: 0.9492 - val_loss: 0.2862 - val_accuracy: 0.8603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the trained model\n",
        "transformer.save('tianliu_525004380_project2_transformer_trained_valacc0.8603.model.h5')\n",
        "transformer.save('tianliu_525004380_project2_transformer_trained_valacc0.8603.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEJQvJ7LwTqG",
        "outputId": "ec15d6cd-9b23-43bc-b85f-7594e73187de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_2_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tianliu_525004380_project2_transformer_trained_valacc0.8603.model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tianliu_525004380_project2_transformer_trained_valacc0.8603.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot the train and val performance"
      ],
      "metadata": {
        "id": "HDlvYm87gk49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training and validation loss and acc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"r\", marker=\"o\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", marker=\"o\",label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"r\", marker=\"o\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", marker=\"o\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "8416579QgVB1",
        "outputId": "4394ae47-f1d6-439c-b88f-5c4069cf8dcf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check translation performance on val dataset"
      ],
      "metadata": {
        "id": "Ua6Rom2lf7E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample some sentences as test data to see performance\n",
        "\n",
        "test_input_texts = [pair[0] for pair in val_pairs]\n",
        "test_output_texts = [pair[1] for pair in val_pairs]\n",
        "\n",
        "# test_input_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "from numpy import random\n",
        "\n",
        "num_sample = 10\n",
        "idx = [random.randint(0, len(val_pairs)) for i in range(num_sample)]\n",
        "\n",
        "for i in idx:\n",
        "  input_sentence = test_input_texts[i]\n",
        "  target = test_output_texts[i]\n",
        "\n",
        "  print(\"idx =\", i)\n",
        "  print(\"-> input\")\n",
        "  print(input_sentence)\n",
        "  print(\"-> target\")\n",
        "  print(strip_markers(target))\n",
        "  print(\"-> predicted\")\n",
        "  print(strip_markers(decode_sequence(input_sentence)))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xziibla_f6GK",
        "outputId": "9e0a521b-03a7-485d-b8b4-7ea176a7b5cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx = 401\n",
            "-> input\n",
            "a j a e c f a f a e c g a f c e a j a g a e c g a i a e b f b f a d c g c e c f a g c e c e a j c f c e b f \n",
            "-> target\n",
            "c f a e d c g a e f c e c g a e i b f a e k b f c g c e a d ed ee a i l m ef a g j eg c f c e c e a g ej ek a j eh ei el a f h em a f g fd c f c e b f a j ff fg fh a j e fe fi\n",
            "-> predicted\n",
            "c f a e d c g a e f c e c e c g a e j b f b f c g c f a d m ed a i k l ee a g h ef c e c f a j eg eh ei c f a g ej ek b e c f c f b f a j fd fe ff a h el em fg b f a j fh fi a k ej fj\n",
            "\n",
            "idx = 505\n",
            "-> input\n",
            "a d b f a i a g c e b e a g a i c g a g a f b e b f b g c g a i a h c d b d a e a f b g c e b e b g b e \n",
            "-> target\n",
            "b f c e b e a g e f c g b e b f a f i j b g a g k l c g a i h m ed c d b d b g c e a f eh ei a e ej a h ef eg ek b e b g a i el em fd a g ee fe b e a i g ff fg a d d fh\n",
            "-> predicted\n",
            "b f c e b e a g e f c g b e b f a f i j b g a g k l b g a i h m ed c d b d b g c e a f eh ei b e a i eg ej ek b e a i ef el em b g a f fd fe b e a i h ff fg a j d g fh\n",
            "\n",
            "idx = 22\n",
            "-> input\n",
            "a f a f a g b e a e a g c g c f b f a j b g c f a g a i a i c g b f b f c g a k a k a d c d c f b g c f b e \n",
            "-> target\n",
            "b e c g c f a g e f a e g a g d h b f a f i j b g c f c g b f b f a i ed ee ef c g c d c f a d ei ej b g a k ek el c f a k em fd a i eg eh fe b e a g ff fg a j l m fh a f k fi\n",
            "-> predicted\n",
            "b e c g b f a g e f a e g a e h a g d d b f c f b g c g b f b f c g a i ee ef eg c g a i ed eh ei c f b f a k ek el b g a k em fd c f a i ej fe ff a j l m fg a f j fh a f i fi\n",
            "\n",
            "idx = 376\n",
            "-> input\n",
            "a d a d a i b g c g a e c f a e a k b d c e a d a k b e c f a k c f a d c e b d \n",
            "-> target\n",
            "b g c g c f a e f a i d e g b d c e a k i j a e k a d h l b e c f a k ed ee c f c e b d a d eh ei a k eg ej a d ef ek a d m el\n",
            "-> predicted\n",
            "b g c g c e c f a e g a f f h a i d e i b d b e c f a k l m c f a k ed ee a k j ef a d j eg c f b d a d ei ej a g eh ek\n",
            "\n",
            "idx = 260\n",
            "-> input\n",
            "a j a j c f c d b g a k a f c f a j c d a k a e b g a d b e c g c d b d a g b f c e \n",
            "-> target\n",
            "c f c d b g a j d e f c f c d b g a e j b e c g a d l m a k k ed c d a j i ee ef a f h eg b d a k eh ei b f c e a g ek el a j g ej em\n",
            "-> predicted\n",
            "c f c d b g a j d e f c f c f c d b g b g c e a d l m a k k ed b d a j i j ee ef a k h eg b d a j g eh ei b f c e a g ek el em\n",
            "\n",
            "idx = 254\n",
            "-> input\n",
            "a e a i a g c g a e a g a h a e c e a e a k a f b d b e c e b d c f c e c g \n",
            "-> target\n",
            "c g c e a e e b d b e a f g h c e a k i j a e k b d a h f l m c f a g ed ee a e ef a g d eg c e c g a i eh ei ej a e ek\n",
            "-> predicted\n",
            "c g c g c f a e f b f b e a f h i b e a k j k a e l a h e g m b d c f a h ed ee ef c e a i d eg eh c g a g ei ej a e ek\n",
            "\n",
            "idx = 525\n",
            "-> input\n",
            "a i a f b d c e c d a g a i a f a f c d c g a f a e b d c f a g b g c g c g a d c e b f \n",
            "-> target\n",
            "b d c e a f d e c d c d c g a f h i b d a e k c f a f l m a f j ed b g c g a g ef eg c g a i ee eh ei c e b f a d ek el a g ej em a i f g fd\n",
            "-> predicted\n",
            "b d c e a f d e c d c f c d c g a f i j b d a e l b g c g a g ed ee a f m ef c g a i k eg eh c g b f a e ek a i ei ej el b f b f a i f em fd\n",
            "\n",
            "idx = 400\n",
            "-> input\n",
            "a i a f a j c f a j a j c e b d c d b e b d c f c e a g b g b g b f \n",
            "-> target\n",
            "c f c e b d c d a j e f g b e b d a j h i j c f a j d k l c e a f m ed b g b g a g ef eg b f a i ee eh ei\n",
            "-> predicted\n",
            "c f c e b d b e a j e f g b e b d a j h i j c f a j d k l c e b g b g b f a g ef eg a i ed ee eh b f a i m ei ej\n",
            "\n",
            "idx = 225\n",
            "-> input\n",
            "a g a f a j b f b d a e a e a e b e a d b e b d a e a h c d b g a j c e b d b g \n",
            "-> target\n",
            "b f b d b e a e f a e g a e h a j d e i b e b d a d k l a f j m c d b g c e b d b g a j eg eh ei a h ee ef ej a e ek a g ed el\n",
            "-> predicted\n",
            "b f b d b e a e f a e g b e b e b d a d j a f i k b d c d b g b g c e b g a j ef eg eh a h ed ee ei a h l m ej a e ek a g k el\n",
            "\n",
            "idx = 36\n",
            "-> input\n",
            "a g a f a e a k a g a f b e a h b d b e c g b d c d c e a d c e a e a d a k b d b f c e \n",
            "-> target\n",
            "b e b d b e c g a h e f g a f d h b d a g i j c d a k k l a e m c e a f ed ee c e b d b f a k eh ei c e a d ej ek a e el a d eg em a g ef fd\n",
            "-> predicted\n",
            "b f b f b e b g a h e f g a f d h c g a e j b d a g k l a k i m a e ed c d c e b d b f a k eh ei b d c f a d ej ek a d eg el c e a g em fd\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrain on the entire given dataset"
      ],
      "metadata": {
        "id": "ZN5FsGRvjPV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_full = make_dataset(text_pairs)"
      ],
      "metadata": {
        "id": "hBI_CPWJkftp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 1024\n",
        "num_heads = 8\n",
        "vocab_size = 100\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"input\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"output\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "history = transformer.fit(train_ds_full, epochs=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f5t5uRvjUwB",
        "outputId": "12e8c7be-180a-4c12-ba16-b503d76fe783"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "79/79 [==============================] - 15s 135ms/step - loss: 2.2407 - accuracy: 0.1511\n",
            "Epoch 2/80\n",
            "79/79 [==============================] - 11s 133ms/step - loss: 1.2948 - accuracy: 0.3004\n",
            "Epoch 3/80\n",
            "79/79 [==============================] - 11s 135ms/step - loss: 1.1640 - accuracy: 0.3426\n",
            "Epoch 4/80\n",
            "79/79 [==============================] - 11s 135ms/step - loss: 1.0612 - accuracy: 0.3734\n",
            "Epoch 5/80\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 1.0117 - accuracy: 0.3937\n",
            "Epoch 6/80\n",
            "79/79 [==============================] - 11s 137ms/step - loss: 0.9571 - accuracy: 0.4144\n",
            "Epoch 7/80\n",
            "79/79 [==============================] - 11s 138ms/step - loss: 0.9300 - accuracy: 0.4272\n",
            "Epoch 8/80\n",
            "79/79 [==============================] - 11s 138ms/step - loss: 0.8818 - accuracy: 0.4455\n",
            "Epoch 9/80\n",
            "79/79 [==============================] - 11s 138ms/step - loss: 0.8591 - accuracy: 0.4557\n",
            "Epoch 10/80\n",
            "79/79 [==============================] - 11s 139ms/step - loss: 0.8312 - accuracy: 0.4691\n",
            "Epoch 11/80\n",
            "79/79 [==============================] - 11s 139ms/step - loss: 0.7982 - accuracy: 0.4838\n",
            "Epoch 12/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.7742 - accuracy: 0.4973\n",
            "Epoch 13/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.7443 - accuracy: 0.5154\n",
            "Epoch 14/80\n",
            "79/79 [==============================] - 11s 139ms/step - loss: 0.7304 - accuracy: 0.5246\n",
            "Epoch 15/80\n",
            "79/79 [==============================] - 11s 139ms/step - loss: 0.6978 - accuracy: 0.5429\n",
            "Epoch 16/80\n",
            "79/79 [==============================] - 11s 139ms/step - loss: 0.6801 - accuracy: 0.5559\n",
            "Epoch 17/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.6494 - accuracy: 0.5742\n",
            "Epoch 18/80\n",
            "79/79 [==============================] - 11s 139ms/step - loss: 0.6302 - accuracy: 0.5903\n",
            "Epoch 19/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.6077 - accuracy: 0.6050\n",
            "Epoch 20/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.5863 - accuracy: 0.6192\n",
            "Epoch 21/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.5697 - accuracy: 0.6326\n",
            "Epoch 22/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.5522 - accuracy: 0.6474\n",
            "Epoch 23/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.5323 - accuracy: 0.6590\n",
            "Epoch 24/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.5197 - accuracy: 0.6696\n",
            "Epoch 25/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.4996 - accuracy: 0.6796\n",
            "Epoch 26/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.4877 - accuracy: 0.6883\n",
            "Epoch 27/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.4675 - accuracy: 0.6989\n",
            "Epoch 28/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.4529 - accuracy: 0.7076\n",
            "Epoch 29/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.4405 - accuracy: 0.7154\n",
            "Epoch 30/80\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 0.4237 - accuracy: 0.7265\n",
            "Epoch 31/80\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 0.4148 - accuracy: 0.7337\n",
            "Epoch 32/80\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 0.3982 - accuracy: 0.7437\n",
            "Epoch 33/80\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 0.3879 - accuracy: 0.7515\n",
            "Epoch 34/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.3735 - accuracy: 0.7606\n",
            "Epoch 35/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.3629 - accuracy: 0.7687\n",
            "Epoch 36/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.3539 - accuracy: 0.7750\n",
            "Epoch 37/80\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 0.3395 - accuracy: 0.7842\n",
            "Epoch 38/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.3316 - accuracy: 0.7894\n",
            "Epoch 39/80\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 0.3190 - accuracy: 0.7965\n",
            "Epoch 40/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.3130 - accuracy: 0.8016\n",
            "Epoch 41/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.3057 - accuracy: 0.8068\n",
            "Epoch 42/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.2951 - accuracy: 0.8147\n",
            "Epoch 43/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2937 - accuracy: 0.8168\n",
            "Epoch 44/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.2810 - accuracy: 0.8237\n",
            "Epoch 45/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2749 - accuracy: 0.8288\n",
            "Epoch 46/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2668 - accuracy: 0.8347\n",
            "Epoch 47/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.2581 - accuracy: 0.8396\n",
            "Epoch 48/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2539 - accuracy: 0.8438\n",
            "Epoch 49/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.2448 - accuracy: 0.8492\n",
            "Epoch 50/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.2389 - accuracy: 0.8529\n",
            "Epoch 51/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2312 - accuracy: 0.8585\n",
            "Epoch 52/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2243 - accuracy: 0.8628\n",
            "Epoch 53/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2175 - accuracy: 0.8680\n",
            "Epoch 54/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.2106 - accuracy: 0.8719\n",
            "Epoch 55/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.2065 - accuracy: 0.8744\n",
            "Epoch 56/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.2020 - accuracy: 0.8794\n",
            "Epoch 57/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1937 - accuracy: 0.8843\n",
            "Epoch 58/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1885 - accuracy: 0.8876\n",
            "Epoch 59/80\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 0.1783 - accuracy: 0.8933\n",
            "Epoch 60/80\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 0.1772 - accuracy: 0.8952\n",
            "Epoch 61/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1693 - accuracy: 0.8989\n",
            "Epoch 62/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.1658 - accuracy: 0.9018\n",
            "Epoch 63/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1621 - accuracy: 0.9057\n",
            "Epoch 64/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.1529 - accuracy: 0.9100\n",
            "Epoch 65/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.1504 - accuracy: 0.9112\n",
            "Epoch 66/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1426 - accuracy: 0.9159\n",
            "Epoch 67/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1445 - accuracy: 0.9169\n",
            "Epoch 68/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1350 - accuracy: 0.9215\n",
            "Epoch 69/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1347 - accuracy: 0.9221\n",
            "Epoch 70/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1268 - accuracy: 0.9277\n",
            "Epoch 71/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1247 - accuracy: 0.9272\n",
            "Epoch 72/80\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 0.1197 - accuracy: 0.9313\n",
            "Epoch 73/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1177 - accuracy: 0.9327\n",
            "Epoch 74/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1167 - accuracy: 0.9342\n",
            "Epoch 75/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1103 - accuracy: 0.9380\n",
            "Epoch 76/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1070 - accuracy: 0.9399\n",
            "Epoch 77/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1073 - accuracy: 0.9408\n",
            "Epoch 78/80\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 0.1000 - accuracy: 0.9434\n",
            "Epoch 79/80\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.0988 - accuracy: 0.9447\n",
            "Epoch 80/80\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 0.0972 - accuracy: 0.9456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the Final Trained Model"
      ],
      "metadata": {
        "id": "nwYx8JCJhfH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save_weights('tianliu_525004380_project2_transformer_final_0.9331.weights')\n",
        "transformer.save('tianliu_525004380_project2_transformer_final_0.9456.best.h5') # save in h5 format\n",
        "transformer.save('tianliu_525004380_project2_transformer_final_0.9456.best')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnOjnuJOEP6l",
        "outputId": "1774bb62-a7c0-49ad-b165-981435dcd232"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, embedding_10_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tianliu_525004380_project2_transformer_final_0.9456.best/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tianliu_525004380_project2_transformer_final_0.9456.best/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To test the trained model on the testing data"
      ],
      "metadata": {
        "id": "oDFapwt3husC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup working directory"
      ],
      "metadata": {
        "id": "s75LU8p_cODl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwOTYKARay1B",
        "outputId": "9a3efec5-3daa-47e2-dd05-5937450f7561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the following directory to your working directory\n",
        "%cd 'drive/MyDrive/Colab Notebooks/CSCE636_DeepLearning/Project2_MachineTranslation/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPyal10fa4gC",
        "outputId": "7c82dc7b-1b82-4e5b-fd89-0f97efe7d3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/CSCE636_DeepLearning/Project2_MachineTranslation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To load the pretrained model"
      ],
      "metadata": {
        "id": "ek1tXnsLcTBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the model with customized classes, like the Positional Embedding and TransformerEncoder as well as TransformerDecoder, arguments have to be passed to the custom_objects, as shown below. Also, these layers have to be defined by running the following blocks."
      ],
      "metadata": {
        "id": "bDTdiaX2aG6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions # add up the word embedding and position embedding\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        \n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        \n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        \n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        \n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ],
      "metadata": {
        "id": "S9J6CPewbdJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "from tensorflow import keras\n",
        "\n",
        "transformer_loaded = keras.models.load_model(\\\n",
        "                                             'tianliu_525004380_project2_transformer_final.best',\\\n",
        "                                            #  'tianliu_525004380_project2_transformer_final_0.9601.best', \\\n",
        "                                             custom_objects={\"PositionalEmbedding\":PositionalEmbedding, \\\n",
        "                                                             \"TransformerEncoder\":TransformerEncoder, \\\n",
        "                                                             \"TransformerDecoder\":TransformerDecoder})\n",
        "\n",
        "# # load model in h5 format\n",
        "# transformer_loaded = keras.models.load_model(\\\n",
        "#                                             #  'tianliu_525004380_project2_transformer_final.best.h5', \\\n",
        "#                                              'tianliu_525004380_project2_transformer_trained_valacc0.8701.model.h5', \\\n",
        "#                                              custom_objects={\"PositionalEmbedding\":PositionalEmbedding,\\\n",
        "#                                                              \"TransformerEncoder\":TransformerEncoder, \\\n",
        "#                                                              \"TransformerDecoder\":TransformerDecoder})"
      ],
      "metadata": {
        "id": "YOA7gZhchuVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model by loading the weights\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions # add up the word embedding and position embedding\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        \n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        \n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        \n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        \n",
        "        return self.layernorm_3(attention_output_2 + proj_output)\n",
        "\n",
        "embed_dim = 256\n",
        "dense_dim = 1024\n",
        "num_heads = 8\n",
        "vocab_size = 100\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"input\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"output\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "transformer_loaded = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "transformer_loaded.load_weights('tianliu_525004380_project2_transformer_final_0.9331.weights')"
      ],
      "metadata": {
        "id": "Td4jrovedJ-U",
        "outputId": "4085bd4f-487b-4bee-a613-19b9407751c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0a1c40e450>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_loaded = transformer"
      ],
      "metadata": {
        "id": "zbHn0Q7I93OQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To run trained model on test data"
      ],
      "metadata": {
        "id": "ruHExcOi7gFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: before run the trained model to generate translated text for the testing data, the `source_vectorization` and `target_vectorization` have to be initialized by loading the `train_pairs`, such that the test input can be vectorized using the same training input vocabulary, and the predicted results can be decoded using the same training output vocabulary."
      ],
      "metadata": {
        "id": "Xiy5o2NRcguC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the source_vectorization and target_vectorization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import string\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "strip_chars = string.punctuation\n",
        "# print(type(strip_chars))\n",
        "\n",
        "strip_chars = strip_chars.replace(\"[\", \"\") # will keep [start] and [end] as it is to separate the marker from actual word start and end\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\") # replace punctuation characters with the empty string\n",
        "\n",
        "vocab_size = 40 \n",
        "sequence_length = 100 # max seq length seen in train data is 95\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_pairs_loaded = pickle.load(open('text_pairs', 'rb')) # load the train_pairs\n",
        "\n",
        "train_input_texts = [pair[0] for pair in train_pairs_loaded]\n",
        "train_output_texts = [pair[1] for pair in train_pairs_loaded]\n",
        "\n",
        "source_vectorization.adapt(train_input_texts)\n",
        "target_vectorization.adapt(train_output_texts)\n",
        "\n",
        "print(len(source_vectorization.get_vocabulary()))\n",
        "print(len(target_vectorization.get_vocabulary()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF9q7zciczSZ",
        "outputId": "8f33d76a-b45a-4690-885b-b100259039b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the following decoding process would be long if the testing dataset is large."
      ],
      "metadata": {
        "id": "LXtNpv0Zm-o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the testing input data\n",
        "\n",
        "import pickle\n",
        "\n",
        "# test_input = pickle.load(open('DS_5_test_input', 'rb')) # load the test input data\n",
        "\n",
        "# test_input_texts = [pair[0] for pair in train_pairs]\n",
        "# test_output_texts = [strip_markers(pair[1]) for pair in train_pairs]\n",
        "\n",
        "test_input_texts = [pair[0] for pair in val_pairs]\n",
        "test_output_texts = [strip_markers(pair[1]) for pair in val_pairs]\n",
        "\n",
        "test_input = test_input_texts[-10:]\n",
        "test_output = test_output_texts[-10:]\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 100 # here we use max seq of 100\n",
        "\n",
        "def strip_markers(sentence):\n",
        "  # strip the leading [start] and tailing [end] if existing\n",
        "\n",
        "  words = sentence.split()\n",
        "  if words[0] == \"[start]\":\n",
        "    clean_words = words[1:]\n",
        "  else:\n",
        "    clean_words = words\n",
        "  \n",
        "  if clean_words[-1] == \"[end]\":\n",
        "    clean_words = clean_words[:-1]\n",
        "  else:\n",
        "    clean_words = clean_words\n",
        "\n",
        "  clean_text = \" \".join(clean_words)\n",
        "  return clean_text\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer_loaded(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# run the trained mode to get the predicted output\n",
        "test_pred = []\n",
        "for test_sentence in tqdm(test_input):\n",
        "  test_pred.append(strip_markers(decode_sequence(test_sentence)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU8WRl3mh3hS",
        "outputId": "2de17b68-b69e-4912-ead4-61b65e932577"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [00:24<00:00,  2.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To calculate the \"accuracy for words\""
      ],
      "metadata": {
        "id": "TLtDxKDXcjja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here you can calculate the test accuracy using the \"accuracy for words\" metric (you can use your own or use my implementation below)"
      ],
      "metadata": {
        "id": "cwx7L7A374Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_word_acc(target_texts, pred_texts):\n",
        "\n",
        "  total_ct = 0\n",
        "  match_ct = 0\n",
        "\n",
        "  assert(len(target_texts)==len(pred_texts)) # assert target sentence number match pred sentence number\n",
        "  \n",
        "  text_pairs = zip(target_texts, pred_texts) \n",
        "  for pair in text_pairs: # loop through each sentence\n",
        "    target = pair[0]\n",
        "    pred = pair[1]\n",
        "    print()\n",
        "    print(\"target:\", target)\n",
        "    print(\"predic:\", pred)\n",
        "    \n",
        "    target_words = target.split()\n",
        "    pred_words = pred.split()\n",
        "\n",
        "    total_ct += len(target_words)\n",
        "    min_len = min(len(target_words), len(pred_words))\n",
        "    print('target_len:', len(target_words))\n",
        "    print('pred_len:', len(pred_words))\n",
        "    \n",
        "    m_ct = 0\n",
        "    for i in range(min_len): # loop through each word\n",
        "      if target_words[i] == pred_words[i]:\n",
        "        m_ct += 1\n",
        "        match_ct += 1\n",
        "    \n",
        "    print('m_ct', m_ct)\n",
        "    print('match_ct', match_ct)\n",
        "    print('total_ct', total_ct)\n",
        "    \n",
        "  word_acc = match_ct / total_ct\n",
        "  return word_acc\n",
        "\n",
        "# load the test output data\n",
        "# test_output = pickle.load(open('DS_5_test_output', 'rb'))\n",
        "\n",
        "acc = calculate_word_acc(test_output, test_pred)\n",
        "print(\"testing accuracy is\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2HfL43vh-BS",
        "outputId": "ab760f2d-0fd7-4dc1-fe88-56993571ff28"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "target: b e c g b f c f c d c e a i g h i a h e f j a d d k c e a e m a d l ed b f c f a d ef eg c d a k eh ei b e c f a j ej ek el c e a d em fd a g ee fe c e c f a g fg fh a k ff fi c g a f fj fk\n",
            "predic: b e c g b f c f c d c e a i g h i a h e f j a d d k c e a e m a d l ed c f a g ee ef b f c f a d eh ei c e a k ej ek c f a d el em a g eg fd c e c e c e c f a g fh fi a h ff fg fj a f fe fk\n",
            "target_len: 86\n",
            "pred_len: 86\n",
            "m_ct 45\n",
            "match_ct 45\n",
            "total_ct 86\n",
            "\n",
            "target: b f c g b f a h d e f a e g c f c g c g c e b d a e m b f a i l ed ee b g a k ef eg a d k eh c f a d ei ej a h i j ek b f a e em a e fd a d el fe c g a i h ff fg\n",
            "predic: b f c g b f a h d e f a e g c f c g c g c e b d a e m b f a i l ed ee a d k ef a h i j eg b g a h h eh ei a e ej c f a d ek el a h g em b f e e fe c g c g a i fd ff fg\n",
            "target_len: 74\n",
            "pred_len: 77\n",
            "m_ct 35\n",
            "match_ct 80\n",
            "total_ct 160\n",
            "\n",
            "target: c d b f c g a k e f c f b e a i g h i c e c f a f k l b g c f b g a f ee ef a f ed eg a k m eh a d j ei c g a j d ej ek\n",
            "predic: c d b f c g a k e f c f b e a i g h i c e c f a f k l b g c f b g a f ee ef a f ed eg a k m eh a d j ei c g a j d ej ek\n",
            "target_len: 56\n",
            "pred_len: 56\n",
            "m_ct 56\n",
            "match_ct 136\n",
            "total_ct 216\n",
            "\n",
            "target: b d c d b d c d a e g a g f h a e i b e b g a k k l a g j m b f a e ee c e c f c f a e ei a g eh ej a d eg ek b e a g el em a g ef fd a f ed fe a d e ff c g a j d fg fh c g a f fi fj b g b e a e fm a i fk fl gd\n",
            "predic: b d c d b g c d a e g a g f h a e i b e b g a k k l a g j m b f a e ee c e c f c f a e ei a g eh ej a d eg ek b e a g el em a g ef fd a f ed fe a d e ff c g a j d fg fh c g a f fi fj b g b e a e fm a i fk fl gd\n",
            "target_len: 95\n",
            "pred_len: 95\n",
            "m_ct 94\n",
            "match_ct 230\n",
            "total_ct 311\n",
            "\n",
            "target: b g b f b d c g a g f g b g b g a d i j c d a h h k l a j d e m b d a e ee a g ed ef c d b f a g eh ei a g eg ej\n",
            "predic: b g b f b d c g a g f g b g b g a d i j c d a h h k l a j d e m b d a e ee a g ed ef c d b f a g eh ei a g eg ej\n",
            "target_len: 53\n",
            "pred_len: 53\n",
            "m_ct 53\n",
            "match_ct 283\n",
            "total_ct 364\n",
            "\n",
            "target: b e c g c g c d b d a e h a d g i c g c g a k k l b f a j j m ed a d f ee c e a i e ef eg a k d eh c f c g b g c f a h ek el em c f b g a k fe ff a h ej fd fg c g a g fh fi a g ei fj\n",
            "predic: b e c g c g c d b d a e h a d g i c g c g a k k l b f a j j m ed a d f ee c e a i e ef eg a k d eh c f b g c f a h ej ek el a k ei em c f b g a k fe ff c g a h fd fg fh c g a g fi fj\n",
            "target_len: 83\n",
            "pred_len: 83\n",
            "m_ct 53\n",
            "match_ct 336\n",
            "total_ct 447\n",
            "\n",
            "target: c e c e b e b f b g b f b d b g a e k c e a f l m a e ed a d j ee a g i ef c d a i h eg eh b f a g ei ej a f g ek c f c e a g em fd a i f el fe a h d e ff\n",
            "predic: c e c e b e b f b g b f b d b g a e k c e a f l m a e ed a d j ee a g i ef c d a i h eg eh b f a g ei ej a f g ek c f c e a g em fd a i f el fe a h d e ff\n",
            "target_len: 71\n",
            "pred_len: 71\n",
            "m_ct 71\n",
            "match_ct 407\n",
            "total_ct 518\n",
            "\n",
            "target: c d c e b g c g a j e f g c e c f c f a g j k a d i l c d a g m ed a h d h ee a e ef b g c g b e a g ei ej a d eh ek a e el b d c e a e fe a i em fd ff a f eg fg\n",
            "predic: c d c e b g c g a j e f g c e c f c f a g j k a d i l c d a g m ed a h d h ee a e ef b g c g b e a g ei ej a e ek b d a i eg el em b d a g fd fe a e ff a f eh fg\n",
            "target_len: 74\n",
            "pred_len: 74\n",
            "m_ct 56\n",
            "match_ct 463\n",
            "total_ct 592\n",
            "\n",
            "target: b e b e c g c g a g f g c f a f h i b f a e k a d j l a g e m c e a e ee a d ed ef b g b g a g eh ei b f a k ej ek b f b g a k em fd b e a k fe ff a e fg a i eg el fh a f d fi b g c e a h fj fk fl\n",
            "predic: b e b e c g c g a g f g c f a f h i b f a e k a d j l a g e m c e a e ee a d ed ef b g b g a g eh ei b f a k ej ek b f b g a k em fd b e a k fe ff a e fg a i eg el fh a f d fi b g c e a h fj fk fl\n",
            "target_len: 89\n",
            "pred_len: 89\n",
            "m_ct 89\n",
            "match_ct 552\n",
            "total_ct 681\n",
            "\n",
            "target: b e b e b g b e a g f g b g c g b f a d j k a i h i l a i d e m b e b g c e a i ee ef eg a k ed eh c f a f ei ej\n",
            "predic: b e b e b g b e a g f g b g c g b f a d j k a i h i l a i d e m b e b g c e a i ee ef eg a k ed eh c f a f ei ej\n",
            "target_len: 53\n",
            "pred_len: 53\n",
            "m_ct 53\n",
            "match_ct 605\n",
            "total_ct 734\n",
            "testing accuracy is 0.8242506811989101\n"
          ]
        }
      ]
    }
  ]
}